# CLAUDE.md

This file provides guidance to Claude Code (claude.ai/code) when working with code in this repository.

## Project Overview

This is a **Course Materials RAG (Retrieval-Augmented Generation) System** — a full-stack application that answers questions about course materials using semantic search and Claude AI. The system processes course documents, stores them in a vector database, and uses tool-based retrieval to provide context-aware responses.

## Common Development Commands

### Running the Application
- **Quick start**: `./run.sh` (from project root)
- **Manual backend start**: `cd backend && uv run uvicorn app:app --reload --port 8000`
- **Frontend**: Automatically served from `backend/app.py` at `http://localhost:8000`
- **API docs**: `http://localhost:8000/docs` (auto-generated by FastAPI)

### Dependencies
- **Install**: `uv sync`
- **Add package**: `uv add <package_name>`
- **View lock**: `uv.lock` (commit this file)

### Environment Setup
Create `.env` in project root with:
```
ANTHROPIC_API_KEY=your_key_here
```

## Architecture Overview

### High-Level Flow
1. **User Query** → FastAPI backend (`backend/app.py`)
2. **RAG Processing** → `RAGSystem` orchestrates the workflow
3. **Vector Search** → `VectorStore` (ChromaDB) retrieves relevant content
4. **Tool Execution** → Claude uses `CourseSearchTool` to search during generation
5. **AI Response** → Claude generates response with tool results
6. **Frontend Display** → React-like frontend shows answer + sources

### Key Components

#### Backend (`backend/`)
- **`app.py`**: FastAPI server, handles POST `/api/query` and GET `/api/courses` endpoints
- **`rag_system.py`**: Main orchestrator that coordinates all components
  - `add_course_folder()`: Batch load documents from a directory
  - `query()`: Process user queries with conversation history
  - `get_course_analytics()`: Return course metadata
- **`vector_store.py`**: ChromaDB wrapper for semantic search
  - Collections: `course_metadata` (titles/info), `course_content` (text chunks)
  - Uses `sentence-transformers` embedding model (`all-MiniLM-L6-v2`)
- **`ai_generator.py`**: Anthropic Claude integration with tool calling
  - Handles tool execution loop (Claude calls tools → execute → provide results)
  - System prompt instructs Claude to use search tool for course-specific questions
- **`search_tools.py`**: Defines `CourseSearchTool` (used by Claude) and `ToolManager`
  - Tool accepts `query`, `course_name` (optional), `lesson_number` (optional)
  - Formats results with course/lesson context for Claude
- **`document_processor.py`**: Parses PDF/DOCX/TXT → chunks
  - Extracts course structure (title, lessons) from document
  - Creates `CourseChunk` objects with metadata
- **`session_manager.py`**: Tracks conversation history per session
- **`models.py`**: Pydantic models: `Course`, `Lesson`, `CourseChunk`
- **`config.py`**: Configuration (model, embedding model, chunk sizes, API key)

#### Frontend (`frontend/`)
- **`index.html`**: Simple chat interface
- **`script.js`**: Queries `/api/query`, manages sessions, displays sources
- **`style.css`**: Styling

#### Data
- **`docs/`**: Course documents (PDF/DOCX/TXT) loaded on startup
- **`chroma_db/`**: Persistent vector database created at runtime

### Configuration Constants (`backend/config.py`)
- `ANTHROPIC_MODEL`: Claude model for generation
- `EMBEDDING_MODEL`: `all-MiniLM-L6-v2` for semantic search
- `CHUNK_SIZE`: 800 (text chunk size for chunking)
- `CHUNK_OVERLAP`: 100 (overlap between chunks)
- `MAX_RESULTS`: 5 (max search results)
- `MAX_HISTORY`: 2 (conversation turns to remember per session)

## Important Design Patterns

### Tool-Based Retrieval
Claude doesn't receive search results upfront. Instead:
1. Claude receives the user query and tool definitions
2. Claude decides whether to call `search_course_content` tool
3. Backend executes the tool and provides results
4. Claude generates final response using tool results

See `ai_generator.py:_handle_tool_execution()` for the multi-turn interaction.

### Session Management
Each client gets a `session_id` (UUID) to maintain conversation history. The session tracks only the last `MAX_HISTORY` exchanges. The `/api/query` endpoint creates a session if not provided.

### Chunk-Based Storage
Documents are split into 800-char chunks with 100-char overlap. Each chunk stores:
- Content (text)
- Course title (for filtering)
- Lesson number (for filtering)
- Chunk index (for ordering)

This allows filtering results by course or lesson when searching.

### Duplicate Prevention
`add_course_folder()` checks existing course titles before re-processing documents to avoid storing duplicates.

## Typical Development Tasks

### Adding a New Course Document
1. Place PDF/DOCX/TXT in `docs/` folder
2. Restart backend — startup event calls `rag_system.add_course_folder("../docs")`
3. Frontend immediately has access via search tool

### Modifying the AI System Prompt
Edit `ai_generator.py` line 8 (`SYSTEM_PROMPT`). Current prompt instructs Claude to:
- Use search tool only for course-specific questions
- Provide direct answers without meta-commentary
- Limit to one search per query

### Adding a New Tool
1. Create class inheriting from `Tool` in `search_tools.py`
2. Implement `get_tool_definition()` and `execute()`
3. Register in `rag_system.py` with `self.tool_manager.register_tool()`

### Tweaking Search Quality
Modify `config.py`:
- Increase `CHUNK_SIZE` for longer context
- Adjust `MAX_RESULTS` to return more/fewer results
- Change `EMBEDDING_MODEL` (must be compatible with sentence-transformers)

## Key Files by Purpose

| Purpose | File |
|---------|------|
| Entrypoint | `backend/app.py` |
| Main orchestrator | `backend/rag_system.py` |
| Vector search | `backend/vector_store.py` |
| Claude integration | `backend/ai_generator.py` |
| Tool definitions | `backend/search_tools.py` |
| Config constants | `backend/config.py` |
| Data models | `backend/models.py` |
| Conversation tracking | `backend/session_manager.py` |
| Document parsing | `backend/document_processor.py` |

## Common Debugging

### Vector Store Issues
- **No results from search**: Check `EMBEDDING_MODEL` matches what was used to create existing embeddings
- **Course not appearing**: Verify file is in `docs/` and startup completed; check console for parsing errors

### Claude Tool Not Calling Search
- Check `ai_generator.py` system prompt — it controls when Claude decides to search
- Verify `search_tools.py:CourseSearchTool` is registered in `rag_system.py`

### Session Not Persisting
- `session_manager.py` keeps history in memory (not persistent)
- `MAX_HISTORY` limits conversation turns stored — older messages are dropped

### Frontend Not Updating
- Dev static files have cache-busting headers (`DevStaticFiles` in `app.py`)
- For production, switch to regular `StaticFiles`
